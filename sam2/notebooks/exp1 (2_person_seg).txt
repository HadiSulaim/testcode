In this experiment, we aimed to analyze occlusion events for specific objects after segmentation using the sam2 module. The implementation involved segmenting the objects in video frames, detecting occlusion events, and comparing the occlusion occurrences between the segmented objects.

After segmenting the objects we needed in our data (in the video) using the sam2 module, we generated binary masks for each person in every frame. These masks were stored for further analysis. To detect occlusion events, we implemented a method that directly summed the mask's surface area to calculate the occluded frames for each segmented person.

The occlusion detection algorithm involved checking the overlap between the masks of the objects. Specifically, we calculated the pixel-wise intersection of the masks for each pair of persons. If the overlap exceeded a predefined threshold, it was considered an occlusion event. This threshold was determined based on the expected size of the overlap that would signify a significant occlusion. By summing the surface area of the masks, we could quantify the extent of occlusion for each frame.

We counted the number of frames where occlusion occurred for each object and compared the occlusion events between the segmented objects. This comparison allowed us to analyze the frequency and duration of occlusion for each person, providing insights into their interactions and movements within the video frames.

To visualize the segmentation and occlusion results, we used matplotlib to generate plots illustrating the occlusion events over time. These visualizations helped in understanding the temporal patterns of occlusion and the differences in occlusion occurrences between the objects segmented. The findings were reported in a structured format, highlighting the differences in occlusion occurrences between the objects.

The results of this experiment revealed the frequency and duration of occlusion events for the three segmented persons. The structured approach ensured a comprehensive analysis of occlusion events, leveraging the capabilities of the sam2 module for accurate segmentation and detection. The results provided valuable insights into the interactions and movements of the persons within the video frames, highlighting the differences in occlusion occurrences between them.